# 逻辑回归

## 案例介绍

在这个案例中，我们将使用逻辑回归算法来预测乳腺癌的患者是恶性（Malignant）还是良性（Benign）。

使用乳腺癌数据集来训练逻辑回归模型，并使用该模型来对新的患者进行预测分类。

## 算法原理

逻辑回归是一种用于二分类问题的机器学习算法。它使用一个逻辑函数（sigmoid函数）来将特征变量的线性组合映射到一个概率值，该概率值表示样本属于正类的可能性。

逻辑回归的算法原理如下：

1. 特征权重初始化：初始化特征的权重值。
2. 线性组合计算：将特征和对应的权重相乘，并求和，得到线性组合的值。
3. Sigmoid函数计算：对线性组合的值应用 sigmoid 函数，将其映射到一个概率值（0到1之间）。
4. 损失函数计算：使用对数损失函数来计算预测值与实际标签之间的误差。
5. 梯度下降更新权重：使用梯度下降算法来最小化损失函数，并更新特征的权重值。
6. 重复步骤2到5，直到达到最大迭代次数或收敛条件。

预测新样本的分类：将特征和对应的权重相乘，并求和，然后将线性组合的值通过 sigmoid 函数转换为概率值，根据阈值将概率值转化为分类标签。

## 公式推导

假设我们有一个二分类问题，其中样本标签为 $y \in \{0, 1\}$ 。 逻辑回归模型假设属于类别 1 的概率由下式给出：

```math
P(y=1 \vert X)=\dfrac{1}{1+e^{-(\beta_0+\beta_1 x_1+\beta_2 x_2+\dots+\beta_n x_n)}}
```

其中， $x_1, x_2, \dots, x_n$ 是特征变量， $\beta_1, \beta_2, \dots, \beta_n$ 是对应特征的权重。

对于类别 $0$ 的概率，可以使用 $P(y=0 \vert X)=1-P(y=1 \vert X)$ 得到。

由于几率（事件发生的概率与该事件不发生的概率的比值）为 $\frac{P(y=1 \vert X)}{1-P(y=1 \vert X)}$ ，我们可以对几率取对数得到：

```math
\log\bigg(\dfrac{P(y=1 \vert X)}{1-P(y=1 \vert X)}\bigg)=\log\bigg(\dfrac{\frac{1}{1+e^{-(\beta_0+\beta_1 x_1+\beta_2 x_2+\dots+\beta_n x_n)}}}{1-\frac{1}{1+e^{-(\beta_0+\beta_1 x_1+\beta_2 x_2+\dots+\beta_n x_n)}}}\bigg)=\log\bigg(\dfrac{1}{e^{-(\beta_0+\beta_1 x_1+\beta_2 x_2+\dots+\beta_n x_n)}}\bigg)=\beta_0+\beta_1 x_1+\beta_2 x_2+\dots+\beta_n x_n
```

以上推导得到了逻辑回归模型的对数几率表达式。最大似然估计的思想表明，我们需要最大化给定数据下的对数似然函数，从而找到最优的权重值。

## 数据集

为了完成本案例实现逻辑回归算法的过程，我们将使用经典的乳腺癌数据集，该数据集包含了乳腺癌患者的不同特征。

数据集中的特征包括以下列：

- mean_radius：肿瘤平均半径
- mean_texture：肿瘤平均质地
- mean_perimeter：肿瘤平均周长
- mean_area：肿瘤平均面积
- mean_smoothness：肿瘤平均平滑度

目标列为：

- diagnosis：诊断结果（M-恶性，B-良性）

## 计算步骤

1. 数据加载与预处理：导入乳腺癌数据集并进行数据预处理，包括特征缩放和将特征和目标变量分成训练和测试数据集。
2. 特征选择：选择适当的特征来训练和测试逻辑回归模型。
3. 模型训练与参数估计：使用训练数据集来训练逻辑回归模型，估计特征的权重。
4. 模型评估：使用测试数据集对模型进行评估，并计算准确率、精确率、召回率和F1分数。
5. 预测新样本：使用训练得到的逻辑回归模型来预测新样本的类别。
